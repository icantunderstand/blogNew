---
title: AI探秘-理解模型微调
date: '2025-11-04'
tags: ['AI']
---

## 目录

- [前置概念](#前置概念)
  - [微调方式对比](#微调方式对比)
- [微调过程实现](#微调过程实现)
  - [准备数据集](#准备数据集)
  - [修改模型微调](#修改模型微调)
  - [实现评估工具](#实现评估工具)
  - [微调模型训练过程](#微调模型训练过程)
  - [使用测试集验证训练结果](#使用测试集验证训练结果)
  - [附录](#附录)

在[AI探秘-理解模型预训练](https://icantunderstand.github.io/blogNew/blog/ai/buildLLMTrain)中，我们了解了如何通过预训练得到基座模型。预训练模型虽然具备强大的语言理解和生成能力，但通常需要针对特定任务进行微调（Fine-tuning）才能在实际应用中发挥最佳效果。

微调是在预训练模型的基础上，使用较小的任务特定数据集继续训练，使模型适应特定任务或领域。本文详细介绍微调过程的实现细节。在后续的文章中会实现一个微调的例子熟悉微调的过程。

![微调过程](/static/images/aiStatic/buildLLMTune/tune.png)

## 前置概念

### 微调方式对比

| 对比项       | 指令微调(有监督指令微调)                                                                                           | 分类微调                           |
| ------------ | ------------------------------------------------------------------------------------------------------------------ | ---------------------------------- |
| **定义**     | 让大模型学会"听懂并遵循人类指令"的通用对话和任务能力                                                               | 让模型在特定分类任务上输出离散标签 |
| **数据格式** | 指令-答案对                                                                                                        | 文本-类别标签对                    |
| **输入**     | 指令（Instruction）：用户给出的任务描述或问题                                                                      | 文本（Text）：待分类的输入文本     |
| **输出**     | 答案（Response）：模型应该生成的回应                                                                               | 类别标签（Label）：文本对应的类别  |
| **核心特点** | • 通用性：训练模型理解多种任务指令<br/>• 对话能力：提升模型的对话交互能力<br/>• 对齐优化：使模型输出更符合人类期望 | 针对特定分类任务，输出离散类别标签 |
| **应用场景** | 问答、翻译、总结、代码生成等多种任务                                                                               | 文本分类、情感分析、意图识别等     |

## 微调过程实现

### 准备数据集

#### 数据预处理

数据预处理包括数据清洗、格式化和标准化等步骤：

- **数据清洗**：去除重复数据、异常值、噪声数据
- **格式化**：统一数据格式，确保数据结构一致
- **标准化**：文本长度截断/填充、添加特殊 token、编码统一等

#### 数据集平衡

数据集平衡（Dataset Balance）是指训练数据集中各个类别的样本数量分布是否均匀。

- **平衡数据集**：各类别样本数量大致相等（如各1000个样本）

- **不平衡数据集**：某些类别样本远多于其他类别（如9000/900/100）

- **影响**：模型会偏向多数类别，导致少数类别识别率低。可通过重采样、类别权重、数据增强等方法处理。

#### 数据集划分

数据集通常需要划分为三个部分：**训练集（Training Set）**、**验证集（Validation Set）** 和 **测试集（Test Set）**。

- **训练集（Training Set）**：用于模型训练，更新模型参数
- **验证集（Validation Set）**：用于模型选择和超参数调优，监控训练过程，防止过拟合
- **测试集（Test Set）**：用于最终评估模型性能，**仅在训练完成后使用一次**，不应参与模型调优

##### 划分注意事项

1. **随机划分**：确保每个集合中的数据分布相似
2. **分层采样**：对于分类任务，保持各类别在三个集合中的比例一致
3. **时间序列**：如果是时间序列数据，应按时间顺序划分
4. **数据泄露**：确保测试集完全独立，不参与任何训练过程

#### 数据加载器

数据加载器（DataLoader）是训练过程中负责高效加载和批处理数据的组件，在模型微调中起到关键作用。

| 功能                             | 说明                                                                                                |
| -------------------------------- | --------------------------------------------------------------------------------------------------- |
| **批量加载（Batching）**         | 将多个样本组合成批次（batch），提高 GPU/TPU 利用率<br/>批次大小（batch_size）影响训练速度和内存占用 |
| **数据打乱（Shuffling）**        | 每个 epoch 随机打乱训练数据顺序<br/>避免模型学习到数据顺序相关的模式，提高泛化能力                  |
| **并行加载（Parallel Loading）** | 使用多进程预加载数据，减少 GPU 等待时间<br/>通过 `num_workers` 参数控制并行进程数                   |

### 修改模型微调

在微调中，可以通过添加任务头（Task Head）和控制层的可训练性来实现微调任务。

- **添加任务头（Task Head）** ⭐ **最常用**

  - **分类任务**：在模型输出层添加线性分类层（如 `Linear(hidden_size, num_classes)`）
  - **回归任务**：添加线性回归层
  - **生成任务**：通常直接使用原模型的输出层，无需额外层级
  - **使用频率**：几乎所有分类和回归任务都采用这种方式

- **控制层的可训练性** ⭐ **微调的核心方法**

  添加新的输出层后，需要标记某些层为可训练或不可训练（冻结/解冻），这是微调中的关键策略：

  - **冻结层（不可训练）**：将预训练模型的参数设为不可训练，参数在训练过程中不会更新
  - **解冻层（可训练）**：允许参数在训练过程中更新

  **常见策略**：

  1. **只训练新层**：冻结所有预训练层，只训练新添加的任务头
     - 训练速度快，参数少，不易过拟合
     - 适合小数据集
  2. **部分解冻**：冻结底层（如嵌入层、前几层），解冻顶层
     - 底层学习通用特征，顶层学习任务特定特征
     - 平衡训练效率和模型适应性

#### 实现评估工具

评估工具用于衡量模型在特定任务上的性能表现。

#### 评估指标

| 任务类型     | 评估指标             | 说明                                             |
| ------------ | -------------------- | ------------------------------------------------ |
| **分类任务** | 准确率（Accuracy）   | 正确预测的样本数占总样本数的比例                 |
|              | 精确率（Precision）  | 预测为正类的样本中，真正为正类的比例             |
|              | 召回率（Recall）     | 真正为正类的样本中，被正确预测为正类的比例       |
|              | F1 分数（F1-Score）  | 精确率和召回率的调和平均数                       |
| **生成任务** | 困惑度（Perplexity） | 衡量模型对下一个词预测的不确定性                 |
|              | BLEU 分数            | 评估生成文本与参考答案的相似度（常用于翻译任务） |
|              | ROUGE 分数           | 评估生成文本的召回率和覆盖度（常用于摘要任务）   |

### 微调模型训练过程

微调的训练过程与预训练类似，但通常使用较小的学习率和较少的训练轮次。需要实现类似预训练的训练循环。

### 使用测试集验证训练结果

测试集用于最终评估模型性能，确保模型具有良好的泛化能力。

#### 评估流程

1. **加载最佳模型**：选择验证集上表现最好的 checkpoint
2. **在测试集上评估**：使用测试集数据计算评估指标
3. **分析结果**：检查模型是否过拟合，性能是否符合预期

### 附录

[easy-dataset](https://github.com/ConardLi/easy-dataset)
