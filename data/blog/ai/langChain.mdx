---
title: AI探秘-LangChain使用不完全指南
date: "2025-10-23"
tags: ["AI"]
---

# LangChain使用不完全指南：从入门到精通

LangChain是一个强大的框架，用于构建基于大语言模型(LLM)的应用程序。它提供了丰富的工具和组件，让开发者能够轻松构建复杂的AI应用。本文将带你从基础概念开始，逐步深入LangChain的各个核心功能。

## 目录

1. [什么是LangChain](#什么是langchain)
2. [LangChain包分类](#langchain包分类)
3. [环境搭建](#环境搭建)
4. [核心概念与组件](#核心概念与组件)

## 什么是LangChain

LangChain是一个开源框架，专门用于开发由语言模型驱动的应用程序。它提供了：

- **模块化设计**：将复杂的AI应用分解为可重用的组件
- **链式调用**：将多个组件串联起来形成工作流
- **多模型支持**：支持OpenAI、Anthropic、本地模型等多种LLM
- **丰富的工具集**：包含文档处理、向量数据库、记忆系统等

## LangChain包分类

### 1. 核心包（Core Packages）
- `langchain` - 核心框架
- `langchain-core` - 核心组件

### 2. 合作伙伴包（Partner Packages）
这些是由 LangChain 官方合作伙伴维护的包，通常有官方支持和保证：
- `langchain-openai` - OpenAI 集成
- `langchain-anthropic` - Anthropic 集成

### 3. 社区集成包（Community Integrations）
这些是由社区开发和维护的包：
- `langchain-ollama` - Ollama 集成
- `langchain-community` - 社区贡献的集成

## 环境搭建

```bash
# 安装核心包
pip install langchain
pip install langchain-core
# 这里因为要使用ollama本地模型 所以安装langchain-ollama
pip install langchain-ollama
# 安装社区包（包含更多集成）
pip install langchain-community

```
### 基本使用

<CollapsibleCode title="基础LLM调用示例" language="python">
```python
from langchain_ollama import OllamaLLM
llm = OllamaLLM(model="deepseek-r1:1.5b")
response = llm.invoke("你好，请介绍一下你自己")
print(response)
```
</CollapsibleCode>

## 核心组件

根据[LangChain官方文档](https://docs.langchain.com/oss/python/langchain/overview)，LangChain v1.0的核心组件包括：

### 1. Models - 模型

LangChain提供了标准化的模型接口，支持多种LLM提供商：

<CollapsibleCode title="多模型支持示例" language="python">
```python
# 支持多种模型提供商
from langchain_ollama import OllamaLLM
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# 本地模型
local_llm = OllamaLLM(model="llama2")

# OpenAI模型
openai_llm = ChatOpenAI(model="gpt-3.5-turbo")

# Anthropic模型
anthropic_llm = ChatAnthropic(model="claude-3-sonnet")

# 统一的调用接口
def call_model(llm, prompt):
    return llm.invoke(prompt)

# 可以无缝切换不同模型
response1 = call_model(local_llm, "你好")
response2 = call_model(openai_llm, "你好")
```
</CollapsibleCode>

### 2. Messages - 消息

LangChain使用标准化的消息格式来处理对话：

<CollapsibleCode title="消息格式示例" language="python">
```python
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# 创建不同类型的消息
system_msg = SystemMessage(content="你是一个有用的AI助手")
human_msg = HumanMessage(content="请介绍一下Python")
ai_msg = AIMessage(content="Python是一种高级编程语言...")

# 消息列表
messages = [system_msg, human_msg, ai_msg]

# 使用消息进行对话
from langchain_ollama import OllamaLLM
llm = OllamaLLM(model="llama2")
response = llm.invoke(messages)
```
</CollapsibleCode>

### 3. Tools - 工具

工具让AI能够执行具体操作：

<CollapsibleCode title="工具定义示例" language="python">
```python
from langchain_core.tools import tool

# 定义工具
@tool
def get_weather(city: str) -> str:
    """获取指定城市的天气信息"""
    # 这里应该是真实的API调用
    return f"{city}今天天气晴朗，温度25度"

@tool
def calculate(expression: str) -> str:
    """计算数学表达式"""
    try:
        result = eval(expression)
        return str(result)
    except:
        return "无法计算该表达式"

# 工具列表
tools = [get_weather, calculate]
```
</CollapsibleCode>

### 4. Agents - 智能代理

代理是LangChain的核心，能够使用工具完成任务：

<CollapsibleCode title="创建智能代理" language="python">
```python
from langchain.agents import create_agent
from langchain_ollama import OllamaLLM

# 定义工具
@tool
def get_weather(city: str) -> str:
    """获取天气信息"""
    return f"{city}今天天气晴朗，温度25度"

@tool
def calculate(expression: str) -> str:
    """计算数学表达式"""
    try:
        result = eval(expression)
        return str(result)
    except:
        return "无法计算"

# 创建代理
agent = create_agent(
    model=OllamaLLM(model="llama2"),
    tools=[get_weather, calculate],
    system_prompt="你是一个有用的助手，可以使用工具来帮助用户"
)

# 运行代理
response = agent.invoke({
    "messages": [{"role": "user", "content": "计算 15 * 8，然后告诉我北京的天气"}]
})
```
</CollapsibleCode>

### 5. Short-term Memory - 短期记忆

让AI记住当前对话的上下文：

<CollapsibleCode title="对话记忆示例" language="python">
```python
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_ollama import OllamaLLM

# 创建记忆
memory = ConversationBufferMemory()

# 创建对话链
llm = OllamaLLM(model="llama2")
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# 进行多轮对话
response1 = conversation.predict(input="我叫张三，是一名Python开发者")
response2 = conversation.predict(input="我刚才说我叫什么名字？")
print(response2)  # AI会记住你的名字
```
</CollapsibleCode>

### 6. Streaming - 流式输出

支持实时流式响应：

<CollapsibleCode title="流式输出示例" language="python">
```python
from langchain_ollama import OllamaLLM
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# 创建支持流式输出的LLM
streaming_llm = OllamaLLM(
    model="llama2",
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()]
)

# 流式响应
response = streaming_llm.invoke("请详细解释什么是机器学习")
```
</CollapsibleCode>

### 7. Middleware - 中间件

用于处理请求和响应的中间件：

<CollapsibleCode title="中间件示例" language="python">
```python
from langchain_core.runnables import RunnableLambda
from langchain_ollama import OllamaLLM

# 定义中间件
def log_requests(inputs):
    print(f"收到请求: {inputs}")
    return inputs

def log_responses(outputs):
    print(f"返回响应: {outputs}")
    return outputs

# 创建带中间件的链
llm = OllamaLLM(model="llama2")

# 添加中间件
chain = (
    RunnableLambda(log_requests) 
    | llm 
    | RunnableLambda(log_responses)
)

# 使用链
response = chain.invoke("你好")
```
</CollapsibleCode>

### 8. Structured Output - 结构化输出

将AI输出解析为结构化数据：

<CollapsibleCode title="结构化输出示例" language="python">
```python
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama import OllamaLLM
from pydantic import BaseModel, Field

# 定义输出结构
class CodeReview(BaseModel):
    score: int = Field(description="代码质量评分，1-10分")
    strengths: list[str] = Field(description="代码优点")
    improvements: list[str] = Field(description="改进建议")

# 创建解析器
parser = PydanticOutputParser(pydantic_object=CodeReview)

# 创建提示模板
prompt = ChatPromptTemplate.from_template(
    "请审查以下代码：\n{code}\n{format_instructions}"
)

# 创建链
llm = OllamaLLM(model="llama2")
chain = prompt | llm | parser

# 使用链
result = chain.invoke({
    "code": "def hello(): print('Hello World')",
    "format_instructions": parser.get_format_instructions()
})

print(f"评分：{result.score}")
print(f"优点：{result.strengths}")
```
</CollapsibleCode>


## 延伸阅读

- [LangChain官方文档](https://python.langchain.com/)
- [LangChain GitHub仓库](https://github.com/langchain-ai/langchain)


