---
title: AI探秘-微调实战体验
date: '2025-11-18'
tags: ['AI']
---

## 大模型微调方式概览

| 方法                         | 定义 / 原理                                         | 主要优缺点                                                                                  |
| ---------------------------- | --------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| 全量微调（Full Fine-tuning） | 更新全部参数，使模型完全适应目标任务                | ✅ 效果最佳、可处理与预训练差异极大的场景；❌ 显存/计算成本最高，训练耗时且需大量高质量数据 |
| 参数高效微调（PEFT）         | 冻结大部分权重，只训练少量新增/解冻参数             | ✅ 显著降低显存与计算，便于多任务复用；❌ 调参空间受限，难完全替代全量微调                  |
| LoRA                         | 将原始的高维权重矩阵分解为两个低秩矩阵的乘积        | ✅ 仅需训练 0.1%-1% 参数，效果接近全量；❌ 需在多层插入 LoRA，部署时还要携带适配权重        |
| QLoRA                        | 基座量化到 4/8-bit 后再叠加 LoRA 训练低秩矩阵       | ✅ 显存占用极低，可在消费级 GPU 微调大模型；❌ 依赖量化库，量化噪声可能影响稳定性           |
| Adapter                      | 在 Transformer 层插入小型适配器模块并仅训练该模块   | ✅ 模块化可插拔、参数效率高；❌ 推理需经过适配器，延迟和模型尺寸都会增加                    |
| Prefix / P / Prompt Tuning   | 训练可学习的 prompt tokens / prefix，不改动主干结构 | ✅ 训练参数最少，部署简单；❌ 效果通常不及 LoRA，需频繁调节 prompt 长度与位置               |

## 基于[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)实现微调

### 安装[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)

```bash
# 使用 Python 3.11 创建虚拟环境（放在当前目录的 .venv 文件夹）
python3.11 -m venv .venv

# 激活虚拟环境（Mac / Linux）
source .venv/bin/activate

# 升级基础打包工具，减少安装报错概率
python -m pip install --upgrade pip setuptools wheel

# 在“可编辑模式”下安装 LLaMA-Factory，并额外安装 torch、metrics 相关依赖
pip install -e ".[torch,metrics]" --no-build-isolation
```

### 构建数据集

## 附录

[炼石成丹：大语言模型微调实战系列（二）模型微调篇](https://aws.amazon.com/cn/blogs/china/practical-series-on-fine-tuning-large-language-models-part-two/)
[LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
