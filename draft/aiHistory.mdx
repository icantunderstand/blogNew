---
title: AI探秘-大模型基础原理
date: "2025-09-04"
tags: ["AI"]
---

## 大模型的前世
[架构](./aiHistory/struct.png)
LLM(Large Language Model)是一种神经网络,具有理解、生成和回应类似人类的文本。大模型的大主要因为:
* 模型的参数规模
* 训练使用的海量数据集

一些术语

* 预训练  用大规模、多样化的数据集训练一个大模型，让它学到通用表征与基础能力得到基座模型
* 微调  在已有预训练大模型的基础上，用较小的任务/领域数据继续训练得到微调模型
* 自监督学习 不依赖人工标注，利用数据自身构造“伪标签/预任务”来训练模型，从而学到通用表征与结构 

* 指令微调（Instruction Tuning）：让大模型学会“听懂并遵循人类指令”的通用对话/任务能力。  在指令微调中，标记数据集由指令和答案对组成
* 分类微调（Classification Fine-tuning）：让模型在特定分类任务上输出离散标签。标记数据集由文本及其相关类别标签组成






### 深度学习


### 大模型



## 大模型的今生(生成原理)





